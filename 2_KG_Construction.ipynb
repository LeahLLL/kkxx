{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeahLLL/kkxx/blob/main/2_KG_Construction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHz_qyuLSU2y"
      },
      "source": [
        "\n",
        "### ğŸ““ Practical 2: Deep Dive - Building a Knowledge Graph for a Single Movie\n",
        "\n",
        "**Objective:**\n",
        "In this practical, we'll build a **deep** knowledge graph, modeling the rich internal world of a **single movie**. We will use its plot summary to extract characters, key items, and the interactions between them. This is a common task in \"domain modeling,\" where the goal is to create a detailed, specialized KG about one specific topic.\n",
        "\n",
        "  * Use `spaCy` to process a detailed movie plot summary.\n",
        "  * Identify **Characters**, **Locations**, and **Items** as node types.\n",
        "  * Use **sentence analysis** to infer relationships like `[:INTERACTS_WITH]`.\n",
        "  * Build and visualize a new, highly-connected graph for our chosen movie.\n",
        "  * Compare our programmatic approach to a zero-shot KG generated by an LLM.\n",
        "\n",
        "-----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "1xtVztQcSU23",
        "outputId": "893e98bc-f31c-4978-e0b9-9fd7c64c96be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/12.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91mâ”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.4/12.8 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.3/12.8 MB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/12.8 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”\u001b[0m \u001b[32m11.2/12.8 MB\u001b[0m \u001b[31m107.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m111.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m111.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3mâš  Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "# ==============\n",
        "# SETUP\n",
        "# ==============\n",
        "# Install necessary libraries\n",
        "!pip install spacy networkx pandas matplotlib --quiet\n",
        "\n",
        "# Download the small English model for spaCy\n",
        "!python -m spacy download en_core_web_sm --quiet\n",
        "\n",
        "# Download the movie plots dataset\n",
        "#donload data here: https://www.kaggle.com/datasets/jrobischon/wikipedia-movie-plots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxtXyFnuSU27"
      },
      "source": [
        "-----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "YdxuayIGSU28"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "from spacy import displacy\n",
        "from spacy.matcher import Matcher\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "from itertools import combinations\n",
        "from collections import Counter\n",
        "\n",
        "# Load the spaCy model. Larger models (md, lg) would yield better entity recognition.\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HogfwRe8SU28"
      },
      "source": [
        "-----\n",
        "\n",
        "### Part 1: Named Entity Recognition (NER) Primer\n",
        "\n",
        "NER is the core NLP task for finding and categorizing named entities in text. `spaCy` automatically assigns labels like `PERSON`, `ORG` (organization), etc. This is our primary tool for discovering potential nodes for our graph.\n",
        "\n",
        "-----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "5UBqA5sVSU29",
        "outputId": "dd4cc4a0-e2e1-47a0-df77-0199d0c96c39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entity: 'Titanic', Label: 'ORG' (Companies, agencies, institutions, etc.)\n",
            "Entity: 'James Cameron', Label: 'PERSON' (People, including fictional)\n",
            "Entity: 'Paramount Pictures', Label: 'ORG' (Companies, agencies, institutions, etc.)\n",
            "Entity: 'over $2 billion', Label: 'MONEY' (Monetary values, including unit)\n"
          ]
        }
      ],
      "source": [
        "sentence = \"The movie Titanic, directed by James Cameron, was produced by Paramount Pictures and grossed over $2 billion.\"\n",
        "doc = nlp(sentence)\n",
        "\n",
        "# The `doc.ents` attribute contains the found entities\n",
        "for ent in doc.ents:\n",
        "    print(f\"Entity: '{ent.text}', Label: '{ent.label_}' ({spacy.explain(ent.label_)})\")\n",
        "\n",
        "# We can also visualize it directly in a notebook\n",
        "# displacy.render(doc, style=\"ent\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NI5aQorySU29"
      },
      "source": [
        "-----\n",
        "\n",
        "### Part 2: Loading and Selecting Our Movie Data\n",
        "\n",
        "We'll use two datasets: the MovieLens dataset for movie metadata (titles, IDs) and a Wikipedia dataset for plot summaries. Our goal is to merge them and select a single, well-known movie to model. For this exercise, we'll use **Pulp Fiction**.\n",
        "\n",
        "*Note: You'll need to have the MovieLens \"small\" dataset available in a local folder named `ml-latest-small` or update the path accordingly.*\n",
        "\n",
        "-----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Xgb2jz2lSU29",
        "outputId": "4a1215fd-0c81-40d2-8957-5a080cbf5fce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please download the 'ml-latest-small' dataset from https://grouplens.org/datasets/movielens/\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "index 0 is out of bounds for axis 0 with size 0",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3390711053.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# --- Isolate Our Target Movie ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mMOVIE_ID\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m296\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mMOVIE_TITLE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmovies_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmovies_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'movieId'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mMOVIE_ID\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0mMOVIE_PLOT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummaries\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mMOVIE_ID\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
          ]
        }
      ],
      "source": [
        "# Load the datasets\n",
        "try:\n",
        "    movies_df = pd.read_csv('ml-latest-small/movies.csv')\n",
        "    ratings_df = pd.read_csv('ml-latest-small/ratings.csv')\n",
        "except FileNotFoundError:\n",
        "    print(\"Please download the 'ml-latest-small' dataset from https://grouplens.org/datasets/movielens/\")\n",
        "    # Create empty df to avoid crashing the rest of the script if data is missing\n",
        "    movies_df = pd.DataFrame(columns=['movieId', 'title', 'genres'])\n",
        "\n",
        "plots_df = pd.read_csv('wiki_movie_plots_deduped.csv')\n",
        "\n",
        "# Clean the movie titles to enable merging\n",
        "movies_df['clean_title'] = movies_df['title'].str.replace(r'\\s*\\(\\d{4}\\)$', '', regex=True).str.strip()\n",
        "\n",
        "# Merge the DataFrames to link plots with movie IDs\n",
        "movie_data_with_plots = pd.merge(movies_df, plots_df, left_on='clean_title', right_on='Title', how='inner')\n",
        "\n",
        "# Create a lookup dictionary: {movieId: plot}\n",
        "summaries = pd.Series(movie_data_with_plots['Plot'].values, index=movie_data_with_plots['movieId']).to_dict()\n",
        "\n",
        "# --- Isolate Our Target Movie ---\n",
        "MOVIE_ID = 296\n",
        "MOVIE_TITLE = movies_df[movies_df['movieId'] == MOVIE_ID]['title'].values[0]\n",
        "MOVIE_PLOT = summaries[MOVIE_ID]\n",
        "\n",
        "print(f\"--- Building Knowledge Graph for: {MOVIE_TITLE} ---\")\n",
        "print(f\"Plot Summary (first 500 chars):\\n{MOVIE_PLOT}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgBT_VTFSU2-"
      },
      "source": [
        "-----\n",
        "\n",
        "### Part 3: Character Extraction\n",
        "\n",
        "Let's begin building our graph. The first and most central node will be the movie itself. Then, we'll find all `PERSON` entities in the plot. In a plot summary, a `PERSON` is almost always a **Character**. We'll add each character as a node and link them to the movie with an `[:APPEARS_IN]` relationship.\n",
        "\n",
        "-----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLmGwJegSU3A"
      },
      "outputs": [],
      "source": [
        "# Create a new, empty graph\n",
        "MovieKG = nx.Graph()\n",
        "\n",
        "# Add the central movie node\n",
        "MovieKG.add_node(MOVIE_TITLE, type='Movie')\n",
        "\n",
        "# Process the entire plot with spaCy\n",
        "doc = nlp(MOVIE_PLOT)\n",
        "\n",
        "# Extract unique character names (PERSON entities)\n",
        "characters = sorted(list(set([ent.text for ent in doc.ents if ent.label_ == 'PERSON'])))\n",
        "\n",
        "print(f\"Found {len(characters)} unique character names:\")\n",
        "print(characters)\n",
        "\n",
        "# Add character nodes and link them to the movie\n",
        "for char in characters:\n",
        "    MovieKG.add_node(char, type='Character')\n",
        "    MovieKG.add_edge(MOVIE_TITLE, char, type='APPEARS_IN')\n",
        "\n",
        "print(f\"\\nGraph now has {MovieKG.number_of_nodes()} nodes and {MovieKG.number_of_edges()} edges.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdfjCu2ASU3B"
      },
      "source": [
        "-----\n",
        "\n",
        "### Part 4: Inferring Character Interactions\n",
        "\n",
        "How do we know if two characters interacted? We can use a powerful heuristic: **if two character names appear in the same sentence, we infer an `[:INTERACTS_WITH]` relationship between them.**\n",
        "\n",
        "-----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4yK9_XuESU3B"
      },
      "outputs": [],
      "source": [
        "# Iterate through each sentence in the plot summary\n",
        "for sentence in doc.sents:\n",
        "    # Find all characters mentioned in this single sentence\n",
        "    chars_in_sentence = [char for char in characters if char in sentence.text]\n",
        "\n",
        "    # If 2 or more characters are in the sentence, create an edge for each unique pair\n",
        "    if len(chars_in_sentence) >= 2:\n",
        "        for char1, char2 in combinations(chars_in_sentence, 2):\n",
        "            MovieKG.add_edge(char1, char2, type='INTERACTS_WITH')\n",
        "\n",
        "print(\"Interaction edges added!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKtYl-PnSU3B"
      },
      "source": [
        "-----\n",
        "\n",
        "### Part 5: Extracting Other Entities (Locations, Items, etc.)\n",
        "\n",
        "Characters interact with more than just each other. Using a broader entity map, we can extract locations, organizations, and key items. We'll use the same sentence-based heuristic to link characters to these new entities.\n",
        "\n",
        "-----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dzt1hEL3SU3C"
      },
      "outputs": [],
      "source": [
        "# A map to categorize spaCy labels into our desired KG node types\n",
        "ENTITY_TYPE_MAP = {\n",
        "    'GPE': 'Location', 'LOC': 'Location', 'FAC': 'Location',\n",
        "    'ORG': 'Organization', 'NORP': 'Faction',\n",
        "    'PRODUCT': 'Item', 'WORK_OF_ART': 'Item',\n",
        "    'EVENT': 'PlotPoint', 'LAW': 'Concept'\n",
        "}\n",
        "\n",
        "new_entities = {} # { 'name': 'type' }\n",
        "\n",
        "# Extract entities using the map\n",
        "for ent in doc.ents:\n",
        "    if ent.label_ in ENTITY_TYPE_MAP:\n",
        "        new_entities[ent.text.strip()] = ENTITY_TYPE_MAP[ent.label_]\n",
        "\n",
        "# Add a custom rule for \"the briefcase,\" a key item the model might miss\n",
        "matcher = Matcher(nlp.vocab)\n",
        "pattern = [{\"LOWER\": \"the\"}, {\"LOWER\": \"briefcase\"}]\n",
        "matcher.add(\"BriefcaseRule\", [pattern])\n",
        "if matcher(doc) and 'the briefcase' not in new_entities:\n",
        "    new_entities['the briefcase'] = 'Item'\n",
        "\n",
        "# Add the new entities as nodes to our graph\n",
        "for name, node_type in new_entities.items():\n",
        "    if name not in MovieKG.nodes:\n",
        "        MovieKG.add_node(name, type=node_type)\n",
        "        MovieKG.add_edge(MOVIE_TITLE, name, type='MENTIONED_IN')\n",
        "\n",
        "print(f\"Found {len(new_entities)} new entities to add to the graph:\")\n",
        "print(new_entities)\n",
        "\n",
        "# Link characters to these new entities based on co-occurrence in sentences\n",
        "for sentence in doc.sents:\n",
        "    chars_in_sentence = [char for char in characters if char in sentence.text]\n",
        "    items_in_sentence = [item for item in new_entities if item in sentence.text]\n",
        "\n",
        "    for char in chars_in_sentence:\n",
        "        for item in items_in_sentence:\n",
        "            MovieKG.add_edge(char, item, type='USES_OR_VISITS')\n",
        "\n",
        "print(\"\\nInteraction edges between characters and new entities have been added.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBDvrul5SU3C"
      },
      "source": [
        "-----\n",
        "\n",
        "### Part 6: Verification and Visualization\n",
        "\n",
        "A graph can become too dense to understand visually. First, let's programmatically count our relationships to verify the graph's content. Then, we'll create a visualization to see the overall structure.\n",
        "\n",
        "-----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JClUQOi8SU3C"
      },
      "outputs": [],
      "source": [
        "# Get a list of all relationship types in the graph and count them\n",
        "all_edge_types = [data['type'] for u, v, data in MovieKG.edges(data=True) if 'type' in data]\n",
        "edge_counts = Counter(all_edge_types)\n",
        "\n",
        "print(\"--- Final Knowledge Graph Content ---\")\n",
        "for edge_type, count in edge_counts.items():\n",
        "    print(f\"- {edge_type}: {count} edges\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJrFZ7L8SU3C"
      },
      "source": [
        "-----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jPRDuSABSU3E"
      },
      "outputs": [],
      "source": [
        "# Prepare for drawing the graph\n",
        "pos = nx.spring_layout(MovieKG, seed=42, k=0.9, iterations=50)\n",
        "\n",
        "# Define colors for our node types\n",
        "color_map = {\n",
        "    'Movie': '#a8d8ea', 'Character': '#f3d3a3', 'Location': '#c3e6cb',\n",
        "    'Organization': '#ffb3ba', 'Faction': '#d8b4e2', 'Item': '#f8c8dc',\n",
        "    'PlotPoint': '#ffaaa5', 'Concept': '#d3d3d3'\n",
        "}\n",
        "node_colors = [color_map.get(MovieKG.nodes[node]['type'], '#cccccc') for node in MovieKG.nodes()]\n",
        "\n",
        "# Create the plot\n",
        "plt.figure(figsize=(22, 16))\n",
        "nx.draw(\n",
        "    MovieKG, pos, with_labels=True, node_size=3500, node_color=node_colors,\n",
        "    font_size=10, edge_color='gray', width=1.5\n",
        ")\n",
        "\n",
        "# Draw edge labels for key relationships to reduce clutter\n",
        "edge_labels = nx.get_edge_attributes(MovieKG, 'type')\n",
        "filtered_labels = {k: v for k, v in edge_labels.items() if v not in ['INTERACTS_WITH', 'USES_OR_VISITS']}\n",
        "nx.draw_networkx_edge_labels(MovieKG, pos, edge_labels=filtered_labels, font_color='red', font_size=8)\n",
        "\n",
        "plt.title(f\"Knowledge Graph for '{MOVIE_TITLE}'\", size=25)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQkXPYYuSU3E"
      },
      "source": [
        "-----\n",
        "\n",
        "### Part 7: Comparison - Can an LLM Do Better?\n",
        "\n",
        "Our programmatic approach created a graph based on a simple co-occurrence heuristic. An advanced LLM, with its vast world knowledge, can infer much more specific and accurate relationships in a zero-shot manner. Below is a graph generated from the same plot, showcasing the detailed relationships an LLM can extract.\n",
        "\n",
        "This highlights the trade-off: our method is systematic and scalable, while the LLM's is more nuanced but requires significant computational power and careful prompt engineering.\n",
        "\n",
        "-----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u92ol42qSU3E"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a directed graph\n",
        "G = nx.DiGraph()\n",
        "\n",
        "# --- Define Nodes (Entities) ---\n",
        "characters = [\n",
        "    \"Jules Winnfield\", \"Vincent Vega\", \"Marsellus Wallace\", \"Brett\",\n",
        "    \"Butch Coolidge\", \"Mia Wallace\", \"Lance\", \"Fabienne\",\n",
        "    \"Maynard\", \"Zed\", \"The Gimp\", \"Jimmie\", \"Winston Wolfe\",\n",
        "    \"Pumpkin\", \"Honey Bunny\", \"Marvin\"\n",
        "]\n",
        "items_and_locations = [\"Briefcase\", \"Heroin\", \"Gold Watch\", \"Katana\", \"Shotgun\", \"Chopper\", \"Diner\"]\n",
        "\n",
        "# Add nodes to the graph with a 'type' attribute\n",
        "for char in characters:\n",
        "    G.add_node(char, type='person')\n",
        "for item in items_and_locations:\n",
        "    G.add_node(item, type='item')\n",
        "\n",
        "# --- Define Edges (Relationships) ---\n",
        "edges_with_labels = [\n",
        "    # Jules and Vincent's storyline\n",
        "    (\"Jules Winnfield\", \"Marsellus Wallace\", \"Works for\"),\n",
        "    (\"Vincent Vega\", \"Marsellus Wallace\", \"Works for\"),\n",
        "    (\"Jules Winnfield\", \"Brett\", \"Retrieves briefcase from\"),\n",
        "    (\"Vincent Vega\", \"Brett\", \"Retrieves briefcase from\"),\n",
        "    (\"Jules Winnfield\", \"Brett\", \"Kills\"),\n",
        "    (\"Vincent Vega\", \"Brett\", \"Kills\"),\n",
        "    (\"Vincent Vega\", \"Marvin\", \"Kills (accidentally)\"),\n",
        "    (\"Jules Winnfield\", \"Jimmie\", \"Hides car at house\"),\n",
        "    (\"Winston Wolfe\", \"Jules Winnfield\", \"Helps clean car\"),\n",
        "    (\"Winston Wolfe\", \"Vincent Vega\", \"Helps clean car\"),\n",
        "\n",
        "    # Vincent and Mia's storyline\n",
        "    (\"Vincent Vega\", \"Lance\", \"Buys heroin from\"),\n",
        "    (\"Vincent Vega\", \"Mia Wallace\", \"Escorts\"),\n",
        "    (\"Mia Wallace\", \"Heroin\", \"Overdoses on\"),\n",
        "    (\"Vincent Vega\", \"Lance\", \"Revives Mia with\"),\n",
        "    (\"Lance\", \"Mia Wallace\", \"Helps revive\"),\n",
        "\n",
        "    # Butch's storyline\n",
        "    (\"Marsellus Wallace\", \"Butch Coolidge\", \"Bribes\"),\n",
        "    (\"Butch Coolidge\", \"Marsellus Wallace\", \"Double-crosses\"),\n",
        "    (\"Butch Coolidge\", \"Vincent Vega\", \"Kills\"),\n",
        "    (\"Fabienne\", \"Butch Coolidge\", \"Is girlfriend of\"),\n",
        "    (\"Fabienne\", \"Gold Watch\", \"Forgets to pack\"),\n",
        "    (\"Marsellus Wallace\", \"Butch Coolidge\", \"Chases\"),\n",
        "    (\"Maynard\", \"Butch Coolidge\", \"Captures\"),\n",
        "    (\"Maynard\", \"Marsellus Wallace\", \"Captures\"),\n",
        "    (\"Zed\", \"Marsellus Wallace\", \"R*pes\"),\n",
        "    (\"Butch Coolidge\", \"The Gimp\", \"Knocks out\"),\n",
        "    (\"Butch Coolidge\", \"Maynard\", \"Kills with Katana\"),\n",
        "    (\"Marsellus Wallace\", \"Zed\", \"Shoots with Shotgun\"),\n",
        "    (\"Marsellus Wallace\", \"Butch Coolidge\", \"Forgives\"),\n",
        "    (\"Butch Coolidge\", \"Fabienne\", \"Escapes with on Chopper\"),\n",
        "\n",
        "    # Diner storyline\n",
        "    (\"Pumpkin\", \"Diner\", \"Robs\"),\n",
        "    (\"Honey Bunny\", \"Diner\", \"Robs\"),\n",
        "    (\"Jules Winnfield\", \"Pumpkin\", \"Overpowers\"),\n",
        "]\n",
        "\n",
        "# Add the edges to the graph\n",
        "for u, v, label in edges_with_labels:\n",
        "    G.add_edge(u, v, label=label)\n",
        "\n",
        "# --- Visualization ---\n",
        "plt.figure(figsize=(22, 22))\n",
        "\n",
        "# Use a spring layout to position nodes automatically\n",
        "pos = nx.spring_layout(G, k=1.3, iterations=70, seed=42)\n",
        "\n",
        "# Define node colors and sizes based on their type\n",
        "node_colors = [\"skyblue\" if G.nodes[node]['type'] == 'person' else \"lightgreen\" for node in G.nodes]\n",
        "node_sizes = [4000 if G.nodes[node]['type'] == 'person' else 2800 for node in G.nodes]\n",
        "\n",
        "# Draw the graph components\n",
        "nx.draw_networkx_nodes(G, pos, node_size=node_sizes, node_color=node_colors, alpha=0.9, linewidths=1.5, edgecolors='black')\n",
        "nx.draw_networkx_edges(G, pos, arrowstyle='->', arrowsize=25, edge_color='darkgray', width=2.0, connectionstyle='arc3,rad=0.1')\n",
        "nx.draw_networkx_labels(G, pos, font_size=12, font_family='sans-serif', font_weight='bold')\n",
        "edge_labels = nx.get_edge_attributes(G, 'label')\n",
        "nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_color='firebrick', font_size=10)\n",
        "\n",
        "# Display the final plot\n",
        "plt.title(\"Pulp Fiction Knowledge Graph\", size=30)\n",
        "plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"pulp_fiction_kg.png\", format=\"PNG\", dpi=300)\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zuUtC9_DIxT2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}